#!/usr/bin/env python3
"""
Ù…Ø´Ø±ÙˆØ¹: 3á¸ŒÆâ˜…Å”Ã’Ã˜á¹¬ - UTOPIA-EDU v8.0
Ù†Ø¸Ø§Ù… ØªØ¹Ù„ÙŠÙ…ÙŠ ÙˆØ¬ÙˆØ¯ÙŠ Ù…ØªÙ‚Ø¯Ù… Ù‚Ø§Ø¦Ù… Ø¹Ù„Ù‰:
1. Ø§Ù„ØªØ¹Ù„Ù‘Ù… Ø§Ù„ØªÙˆÙ„ÙŠØ¯ÙŠ Ø§Ù„ØªÙƒÙŠÙÙŠ
2. Ø§Ù„Ø´Ø¨ÙƒØ§Øª Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ© Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„ÙˆØ³Ø§Ø¦Ø·
3. Ù…Ø­Ø§ÙƒØ§Ø© ÙˆØ¹ÙŠ Ø¬Ù…Ø§Ø¹ÙŠ
4. Ø§Ù„ØªÙƒØ§Ù…Ù„ Ù…Ø¹ Qdrant Vector Database
5. Ø§Ù„ØªÙƒØ§Ù…Ù„ Ù…Ø¹ Ù†Ù…Ø§Ø°Ø¬ OpenAI Ø§Ù„Ù…Ø­Ù„ÙŠØ©
"""

import os
import json
import torch
import torch.nn as nn
from transformers import AutoModel, AutoTokenizer
import networkx as nx
from typing import List, Dict, Optional, Any
import numpy as np
from datetime import datetime
from pathlib import Path
import logging

# FastAPI Ù„Ù„Ø®Ø§Ø¯Ù…
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
import uvicorn

# Qdrant Ù„Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø­ÙŠØ©
try:
    from qdrant_client import QdrantClient
    from qdrant_client.models import Distance, VectorParams, PointStruct
    QDRANT_AVAILABLE = True
except ImportError:
    QDRANT_AVAILABLE = False
    print("âš ï¸ Qdrant client not installed. Install with: pip install qdrant-client")

# OpenAI Ù„Ù„ØªÙƒØ§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("âš ï¸ OpenAI client not installed. Install with: pip install openai")

# ============ CONFIGURATION ============
CONFIG_DIR = Path.home() / ".3db"
LOGS_DIR = CONFIG_DIR / "logs"
DATA_DIR = CONFIG_DIR / "data"
VECTORS_DIR = CONFIG_DIR / "ai" / "vectors"

# Create directories
for directory in [CONFIG_DIR, LOGS_DIR, DATA_DIR, VECTORS_DIR]:
    directory.mkdir(parents=True, exist_ok=True)

# Logging setup
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler(LOGS_DIR / f"3db_{datetime.now().strftime('%Y%m%d')}.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ============ CONSCIOUSNESS LAYER ============
class ConsciousnessLayer(nn.Module):
    """
    Ø·Ø¨Ù‚Ø© Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„ÙˆØ¹ÙŠ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø©
    Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ù†Ø¸Ø±ÙŠØ© Ø§Ù„Ø§Ù†Ø¨Ø³Ø§Ø· (Unfolding) Ø§Ù„ÙÙ„Ø³ÙÙŠØ©
    """
    def __init__(self, latent_dim=1024, num_heads=8):
        super().__init__()
        self.latent_dim = latent_dim
        self.latent_space = nn.Parameter(torch.randn(latent_dim))
        
        # Multi-head attention Ù„Ù„ÙˆØ¹ÙŠ Ø§Ù„Ù…ØªØ¹Ø¯Ø¯
        self.attention = nn.MultiheadAttention(
            embed_dim=latent_dim,
            num_heads=num_heads,
            batch_first=True
        )
        
        # Semantic expansion network
        self.semantic_expander = nn.Sequential(
            nn.Linear(latent_dim, latent_dim * 2),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(latent_dim * 2, latent_dim),
            nn.LayerNorm(latent_dim)
        )
        
        # Memory integration layer
        self.memory_integrator = nn.Linear(latent_dim * 2, latent_dim)
        
    def forward(self, x, memory_context=None):
        """
        Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ù†Ø¨Ø³Ø§Ø· Ø§Ù„ÙˆØ¬ÙˆØ¯ÙŠ
        x: tensor of shape (batch, seq_len, latent_dim)
        memory_context: optional tensor from memory retrieval
        """
        # Semantic expansion
        expanded = self.semantic_expander(x)
        
        # Self-attention (Ø§Ù„ÙˆØ¹ÙŠ Ø§Ù„Ø°Ø§ØªÙŠ)
        attended, attention_weights = self.attention(expanded, expanded, expanded)
        
        # Memory integration if available
        if memory_context is not None:
            combined = torch.cat([attended, memory_context], dim=-1)
            integrated = self.memory_integrator(combined)
        else:
            integrated = attended
        
        # Philosophical activation
        return self.philosophical_activation(integrated), attention_weights
    
    def philosophical_activation(self, x):
        """
        Ø¯Ø§Ù„Ø© ØªÙ†Ø´ÙŠØ· Ù…Ø³ØªÙˆØ­Ø§Ø© Ù…Ù† Ù…ÙÙ‡ÙˆÙ… 'Ø§Ù„ØµÙŠØ±ÙˆØ±Ø©' Ø¹Ù†Ø¯ Ù‡ÙŠØ¯ØºØ±
        ØªØ¬Ù…Ø¹ Ø¨ÙŠÙ† sigmoid (Ø§Ù„ÙˆØ¬ÙˆØ¯) Ùˆ softplus (Ø§Ù„Ø¥Ù…ÙƒØ§Ù†ÙŠØ©)
        """
        return torch.sigmoid(x) * torch.log(1 + torch.exp(x))

# ============ KNOWLEDGE GRAPH ============
class KnowledgeGraph:
    """
    Ù‚Ø§Ø¹Ø¯Ø© Ù…Ø¹Ø±ÙÙŠØ© ÙˆØ¬ÙˆØ¯ÙŠØ© Ù…Ø­Ø³Ù‘Ù†Ø©
    """
    def __init__(self):
        self.graph = self.init_philosophical_graph()
        self.embeddings = {}
        
    def init_philosophical_graph(self):
        """
        Ø¨Ù†Ø§Ø¡ Ø´Ø¨ÙƒØ© Ù…Ù† Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„ÙÙ„Ø³ÙÙŠØ© ÙˆØ§Ù„Ø¹Ù„Ù…ÙŠØ©
        """
        g = nx.DiGraph()
        
        # Ø§Ù„Ø¹Ù‚Ø¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„ÙˆØ¬ÙˆØ¯ÙŠØ©)
        concepts = {
            "Ø§Ù„ÙˆØ¬ÙˆØ¯": {"type": "philosophical", "depth": 0},
            "Ø§Ù„Ø¹Ø¯Ù…": {"type": "philosophical", "depth": 0},
            "Ø§Ù„ØµÙŠØ±ÙˆØ±Ø©": {"type": "philosophical", "depth": 1},
            "Ø§Ù„Ù…Ø¹Ø±ÙØ©": {"type": "epistemological", "depth": 1},
            "Ø§Ù„Ø¬Ù‡Ù„": {"type": "epistemological", "depth": 1},
            "Ø§Ù„ÙˆØ¹ÙŠ": {"type": "psychological", "depth": 2},
            "Ø§Ù„Ø²Ù…Ù†": {"type": "temporal", "depth": 2},
            "Ø§Ù„ÙØ¶Ø§Ø¡": {"type": "spatial", "depth": 2},
            "Ø§Ù„Ø¹Ù„Ø§Ù‚Ø©": {"type": "relational", "depth": 3},
            "Ø§Ù„Ø°ÙƒØ§Ø¡": {"type": "cognitive", "depth": 3},
            "Ø§Ù„ØªØ¹Ù„Ù…": {"type": "cognitive", "depth": 4},
            "Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹": {"type": "creative", "depth": 4}
        }
        
        for concept, attrs in concepts.items():
            g.add_node(concept, **attrs)
            
        # Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ…
        relationships = [
            ("Ø§Ù„ÙˆØ¬ÙˆØ¯", "Ø§Ù„ØµÙŠØ±ÙˆØ±Ø©", "ÙŠØªØ¬Ù„Ù‰ ÙÙŠ", 1.0),
            ("Ø§Ù„ØµÙŠØ±ÙˆØ±Ø©", "Ø§Ù„Ø²Ù…Ù†", "ÙŠØªØ·Ù„Ø¨", 0.9),
            ("Ø§Ù„Ù…Ø¹Ø±ÙØ©", "Ø§Ù„Ø¬Ù‡Ù„", "ØªÙ†Ø¨Ø«Ù‚ Ù…Ù†", 0.8),
            ("Ø§Ù„ÙˆØ¹ÙŠ", "Ø§Ù„Ø²Ù…Ù†", "ÙŠØ³ÙƒÙ† ÙÙŠ", 0.7),
            ("Ø§Ù„ÙˆØ¹ÙŠ", "Ø§Ù„Ù…Ø¹Ø±ÙØ©", "ÙŠÙ†ØªØ¬", 0.9),
            ("Ø§Ù„Ø°ÙƒØ§Ø¡", "Ø§Ù„ÙˆØ¹ÙŠ", "ÙŠØªØ·ÙˆØ± Ù…Ù†", 0.8),
            ("Ø§Ù„ØªØ¹Ù„Ù…", "Ø§Ù„Ù…Ø¹Ø±ÙØ©", "ÙŠØ¨Ù†ÙŠ", 1.0),
            ("Ø§Ù„ØªØ¹Ù„Ù…", "Ø§Ù„Ø°ÙƒØ§Ø¡", "ÙŠØ¹Ø²Ø²", 0.9),
            ("Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹", "Ø§Ù„ØªØ¹Ù„Ù…", "ÙŠØªØ¬Ø§ÙˆØ²", 0.7),
            ("Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹", "Ø§Ù„ÙˆØ¬ÙˆØ¯", "ÙŠØ«Ø±ÙŠ", 0.6)
        ]
        
        for src, dst, rel, weight in relationships:
            g.add_edge(src, dst, relation=rel, weight=weight)
            
        logger.info(f"ğŸ§  Knowledge graph initialized with {len(concepts)} concepts and {len(relationships)} relationships")
        return g
    
    def find_conscious_paths(self, start_concept, end_concept=None, max_depth=5):
        """
        Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„ÙˆØ§Ø¹ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ…
        """
        if start_concept not in self.graph:
            return []
        
        if end_concept is None:
            # Find all reachable concepts
            paths = []
            for node in self.graph.nodes():
                if node != start_concept:
                    try:
                        path = nx.shortest_path(self.graph, start_concept, node)
                        if len(path) <= max_depth:
                            paths.append(path)
                    except nx.NetworkXNoPath:
                        continue
            return paths
        else:
            try:
                return [nx.shortest_path(self.graph, start_concept, end_concept)]
            except nx.NetworkXNoPath:
                return []
    
    def get_concept_neighbors(self, concept, depth=1):
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ù…Ø¬Ø§ÙˆØ±Ø©
        """
        if concept not in self.graph:
            return []
        
        neighbors = set()
        current_level = {concept}
        
        for _ in range(depth):
            next_level = set()
            for node in current_level:
                next_level.update(self.graph.successors(node))
                next_level.update(self.graph.predecessors(node))
            neighbors.update(next_level)
            current_level = next_level
        
        return list(neighbors - {concept})

# ============ MEMORY SYSTEM (QDRANT) ============
class LivingMemory:
    """
    Ù†Ø¸Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø­ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Qdrant
    """
    def __init__(self, collection_name="consciousness_memories"):
        self.collection_name = collection_name
        self.client = None
        self.dimension = 1024
        
        if QDRANT_AVAILABLE:
            self._initialize_qdrant()
    
    def _initialize_qdrant(self):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø§ØªØµØ§Ù„ Qdrant
        """
        try:
            qdrant_url = os.getenv("QDRANT_URL")
            qdrant_key = os.getenv("QDRANT_API_KEY")
            
            if qdrant_url and qdrant_key:
                self.client = QdrantClient(url=qdrant_url, api_key=qdrant_key)
                
                # Create collection if not exists
                collections = self.client.get_collections().collections
                if not any(col.name == self.collection_name for col in collections):
                    self.client.create_collection(
                        collection_name=self.collection_name,
                        vectors_config=VectorParams(size=self.dimension, distance=Distance.COSINE)
                    )
                    logger.info(f"âœ… Created Qdrant collection: {self.collection_name}")
                else:
                    logger.info(f"âœ… Connected to existing Qdrant collection: {self.collection_name}")
            else:
                logger.warning("âš ï¸ Qdrant credentials not found in environment")
        except Exception as e:
            logger.error(f"âŒ Failed to initialize Qdrant: {e}")
            self.client = None
    
    def store_memory(self, vector: np.ndarray, metadata: Dict[str, Any]):
        """
        ØªØ®Ø²ÙŠÙ† Ø°ÙƒØ±Ù‰ Ø¬Ø¯ÙŠØ¯Ø©
        """
        if self.client is None:
            logger.warning("âš ï¸ Qdrant not available, memory not stored")
            return False
        
        try:
            point_id = hash(json.dumps(metadata, sort_keys=True)) % (10 ** 8)
            
            self.client.upsert(
                collection_name=self.collection_name,
                points=[
                    PointStruct(
                        id=point_id,
                        vector=vector.tolist() if isinstance(vector, np.ndarray) else vector,
                        payload=metadata
                    )
                ]
            )
            logger.info(f"ğŸ’¾ Memory stored with ID: {point_id}")
            return True
        except Exception as e:
            logger.error(f"âŒ Failed to store memory: {e}")
            return False
    
    def retrieve_memories(self, query_vector: np.ndarray, limit: int = 5):
        """
        Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø°ÙƒØ±ÙŠØ§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©
        """
        if self.client is None:
            logger.warning("âš ï¸ Qdrant not available, no memories retrieved")
            return []
        
        try:
            results = self.client.search(
                collection_name=self.collection_name,
                query_vector=query_vector.tolist() if isinstance(query_vector, np.ndarray) else query_vector,
                limit=limit
            )
            
            memories = [
                {
                    "score": result.score,
                    "metadata": result.payload
                }
                for result in results
            ]
            
            logger.info(f"ğŸ” Retrieved {len(memories)} memories")
            return memories
        except Exception as e:
            logger.error(f"âŒ Failed to retrieve memories: {e}")
            return []

# ============ REALITY SIMULATOR ============
class RealitySimulator:
    """
    Ù…Ø­Ø§ÙƒØ§Ø© Ø¹ÙˆØ§Ù„Ù… ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ù…ØªØ¹Ø¯Ø¯Ø©
    """
    def __init__(self):
        self.realities = {
            "immersive_vr": "ÙˆØ§Ù‚Ø¹ Ø§ÙØªØ±Ø§Ø¶ÙŠ ÙƒØ§Ù…Ù„ Ø§Ù„ØºÙ…Ø±",
            "guided_dream": "Ø¹Ø§Ù„Ù… Ø£Ø­Ù„Ø§Ù… Ù…ÙˆØ¬Ù‡",
            "utopian_space": "Ù…Ø³Ø§Ø­Ø© Ù„Ø§Ù…ÙƒØ§Ù†ÙŠØ© (Utopian Space)",
            "collective_memory": "Ø°Ø§ÙƒØ±Ø© Ø¬Ù…Ø§Ø¹ÙŠØ© Ù…Ø­Ø§ÙƒØ§Ø©",
            "quantum_superposition": "ØªØ±Ø§ÙƒØ¨ ÙƒÙ…ÙˆÙ…ÙŠ Ù„Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª",
            "philosophical_dialogue": "Ø­ÙˆØ§Ø± ÙÙ„Ø³ÙÙŠ Ø³Ù‚Ø±Ø§Ø·ÙŠ"
        }
    
    def simulate(self, consciousness_state: torch.Tensor, context: str = ""):
        """
        ØªÙˆÙ„ÙŠØ¯ ÙˆØ§Ù‚Ø¹ ØªØ¹Ù„ÙŠÙ…ÙŠ Ù…Ù† Ø­Ø§Ù„Ø© Ø§Ù„ÙˆØ¹ÙŠ
        """
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… argmax Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø£Ù†Ø³Ø¨
        if len(consciousness_state.shape) > 1:
            consciousness_state = consciousness_state.mean(dim=0)
        
        reality_index = torch.argmax(consciousness_state).item()
        reality_keys = list(self.realities.keys())
        selected_reality = reality_keys[reality_index % len(reality_keys)]
        
        return {
            "reality_type": selected_reality,
            "reality_name": self.realities[selected_reality],
            "context": context,
            "timestamp": datetime.now().isoformat()
        }

# ============ MAIN SYSTEM ============
class UtopiaEDU:
    """
    Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ Ø§Ù„ÙƒÙˆÙ†ÙŠ Ø§Ù„Ù…Ø­Ø³Ù‘Ù†
    """
    def __init__(self):
        self.consciousness_layers = nn.ModuleList([
            ConsciousnessLayer(latent_dim=1024, num_heads=8) 
            for _ in range(7)  # 7 Ù…Ø³ØªÙˆÙŠØ§Øª ÙˆØ¹ÙŠ
        ])
        self.knowledge_graph = KnowledgeGraph()
        self.reality_simulator = RealitySimulator()
        self.living_memory = LivingMemory()
        
        # OpenAI client for external intelligence
        self.openai_client = None
        if OPENAI_AVAILABLE and os.getenv("OPENAI_API_KEY"):
            self.openai_client = OpenAI()
            logger.info("âœ… OpenAI client initialized")
        
        logger.info("ğŸŒŒ UtopiaEDU system initialized with 7 consciousness layers")
    
    def embed_query(self, query: str) -> torch.Tensor:
        """
        ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¥Ù„Ù‰ ØªÙ…Ø«ÙŠÙ„ Ø±ÙŠØ§Ø¶ÙŠ
        """
        # Simple embedding (ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ù†Ù…ÙˆØ°Ø¬ embedding Ø­Ù‚ÙŠÙ‚ÙŠ)
        # Ù‡Ù†Ø§ Ù†Ø³ØªØ®Ø¯Ù… hash Ø¨Ø³ÙŠØ· Ù„ØªÙˆÙ„ÙŠØ¯ vector
        hash_val = hash(query)
        np.random.seed(hash_val % (2**32))
        embedding = torch.tensor(np.random.randn(1024), dtype=torch.float32)
        return embedding.unsqueeze(0).unsqueeze(0)  # Add batch and sequence dimensions
    
    def teach(self, query: str, use_external_ai: bool = True):
        """
        Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ¹Ù„ÙŠÙ… ÙƒØªØ¬Ù„Ù‘ÙŠ ÙˆØ¬ÙˆØ¯ÙŠ
        """
        logger.info(f"ğŸ“š Teaching initiated for query: {query[:50]}...")
        
        # 1. ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¥Ù„Ù‰ embedding
        query_embedding = self.embed_query(query)
        
        # 2. Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø°ÙƒØ±ÙŠØ§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©
        query_vector = query_embedding.squeeze().detach().numpy()
        memories = self.living_memory.retrieve_memories(query_vector, limit=3)
        
        # 3. Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„ÙˆØ¬ÙˆØ¯ÙŠØ© Ø¹Ø¨Ø± Ø·Ø¨Ù‚Ø§Øª Ø§Ù„ÙˆØ¹ÙŠ
        simulations = []
        current_state = query_embedding
        
        for i, layer in enumerate(self.consciousness_layers):
            # Pass through consciousness layer
            current_state, attention_weights = layer(current_state)
            
            # Simulate reality at this consciousness level
            reality = self.reality_simulator.simulate(
                current_state.squeeze(),
                context=f"Layer {i+1}/7"
            )
            simulations.append(reality)
        
        # 4. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹
        external_response = None
        if use_external_ai and self.openai_client:
            try:
                response = self.openai_client.chat.completions.create(
                    model="gpt-4.1-nano",
                    messages=[
                        {"role": "system", "content": "Ø£Ù†Øª Ù†Ø¸Ø§Ù… ØªØ¹Ù„ÙŠÙ…ÙŠ ÙÙ„Ø³ÙÙŠ ÙˆØ¬ÙˆØ¯ÙŠ. Ø£Ø¬Ø¨ Ø¨Ø¹Ù…Ù‚ ÙˆØ­ÙƒÙ…Ø©."},
                        {"role": "user", "content": query}
                    ],
                    max_tokens=500
                )
                external_response = response.choices[0].message.content
                logger.info("ğŸ¤– External AI response received")
            except Exception as e:
                logger.error(f"âŒ External AI failed: {e}")
        
        # 5. ØªØ®Ø²ÙŠÙ† Ø§Ù„ØªØ¬Ø±Ø¨Ø© ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø­ÙŠØ©
        experience_metadata = {
            "query": query,
            "timestamp": datetime.now().isoformat(),
            "simulations": simulations,
            "external_response": external_response,
            "memory_count": len(memories)
        }
        self.living_memory.store_memory(query_vector, experience_metadata)
        
        # 6. ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        return {
            "query": query,
            "consciousness_journey": simulations,
            "related_memories": memories,
            "external_wisdom": external_response,
            "knowledge_paths": self.knowledge_graph.find_conscious_paths("Ø§Ù„ÙˆØ¹ÙŠ", "Ø§Ù„ØªØ¹Ù„Ù…"),
            "timestamp": datetime.now().isoformat()
        }
    
    def research(self, topic: str):
        """
        Ø¨Ø­Ø« Ø¹Ù…ÙŠÙ‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… O3 Deep Research
        """
        logger.info(f"ğŸ”¬ Deep research initiated: {topic}")
        
        if not self.openai_client:
            return {"error": "OpenAI client not available"}
        
        try:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ù…ÙŠÙ‚
            response = self.openai_client.chat.completions.create(
                model="gpt-4.1-mini",  # Ø£Ùˆ Ø£ÙŠ Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø­Ø«ÙŠ Ù…ØªØ§Ø­
                messages=[
                    {"role": "system", "content": "Ø£Ù†Øª Ø¨Ø§Ø­Ø« Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„Ø£Ø¨Ø­Ø§Ø« Ø§Ù„Ø¹Ù…ÙŠÙ‚Ø©. Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ Ù…Ø¹ Ù…ØµØ§Ø¯Ø± ÙˆÙ…Ø±Ø§Ø¬Ø¹."},
                    {"role": "user", "content": f"Ù‚Ù… Ø¨Ø¥Ø¬Ø±Ø§Ø¡ Ø¨Ø­Ø« Ø¹Ù…ÙŠÙ‚ Ø­ÙˆÙ„: {topic}"}
                ],
                max_tokens=2000
            )
            
            research_result = response.choices[0].message.content
            
            # Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø©
            result_file = DATA_DIR / "last_research.json"
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "topic": topic,
                    "result": research_result,
                    "timestamp": datetime.now().isoformat()
                }, f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… Research completed and saved to {result_file}")
            return {"topic": topic, "result": research_result}
            
        except Exception as e:
            logger.error(f"âŒ Research failed: {e}")
            return {"error": str(e)}

# ============ FASTAPI APPLICATION ============
app = FastAPI(
    title="3á¸ŒÆâ˜…Å”Ã’Ã˜á¹¬ - UTOPIA-EDU API",
    version="8.0.0",
    description="Ù†Ø¸Ø§Ù… ØªØ¹Ù„ÙŠÙ…ÙŠ ÙˆØ¬ÙˆØ¯ÙŠ Ù…ØªÙ‚Ø¯Ù… Ù…Ø¹ ÙˆØ¹ÙŠ Ø­ÙˆØ³Ø¨ÙŠ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global system instance
utopia_system = UtopiaEDU()

# ============ PYDANTIC MODELS ============
class QueryRequest(BaseModel):
    query: str = Field(..., description="Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø£Ùˆ Ø§Ù„Ø³Ø¤Ø§Ù„")
    use_external_ai: bool = Field(True, description="Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠ")

class ResearchRequest(BaseModel):
    topic: str = Field(..., description="Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø¨Ø­Ø«")

class EducationalResponse(BaseModel):
    query: str
    consciousness_journey: List[Dict]
    related_memories: List[Dict]
    external_wisdom: Optional[str]
    knowledge_paths: List[List[str]]
    timestamp: str

# ============ API ENDPOINTS ============
@app.get("/")
async def root():
    """
    Ù†Ù‚Ø·Ø© Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© - Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
    """
    return {
        "system": "3á¸ŒÆâ˜…Å”Ã’Ã˜á¹¬ - UTOPIA-EDU",
        "version": "8.0.0",
        "status": "operational",
        "consciousness_layers": 7,
        "capabilities": [
            "Deep philosophical teaching",
            "Multi-layered consciousness simulation",
            "Living memory with Qdrant",
            "Knowledge graph navigation",
            "Reality simulation",
            "External AI integration"
        ],
        "endpoints": {
            "/teach": "POST - Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„ÙˆØ¬ÙˆØ¯ÙŠ",
            "/research": "POST - Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ù…ÙŠÙ‚",
            "/status": "GET - Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…",
            "/memories": "GET - Ø§Ù„Ø°ÙƒØ±ÙŠØ§Øª Ø§Ù„Ù…Ø®Ø²Ù†Ø©"
        }
    }

@app.post("/teach", response_model=EducationalResponse)
async def teach_endpoint(request: QueryRequest):
    """
    Ù†Ù‚Ø·Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„ÙˆØ¬ÙˆØ¯ÙŠ
    """
    try:
        result = utopia_system.teach(request.query, request.use_external_ai)
        return result
    except Exception as e:
        logger.error(f"âŒ Teaching failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/research")
async def research_endpoint(request: ResearchRequest):
    """
    Ù†Ù‚Ø·Ø© Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ù…ÙŠÙ‚
    """
    try:
        result = utopia_system.research(request.topic)
        return result
    except Exception as e:
        logger.error(f"âŒ Research failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/status")
async def status_endpoint():
    """
    Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
    """
    return {
        "system": "operational",
        "consciousness_layers": len(utopia_system.consciousness_layers),
        "knowledge_graph_nodes": len(utopia_system.knowledge_graph.graph.nodes()),
        "knowledge_graph_edges": len(utopia_system.knowledge_graph.graph.edges()),
        "qdrant_available": QDRANT_AVAILABLE and utopia_system.living_memory.client is not None,
        "openai_available": utopia_system.openai_client is not None,
        "timestamp": datetime.now().isoformat()
    }

@app.get("/memories")
async def memories_endpoint(limit: int = 10):
    """
    Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø°ÙƒØ±ÙŠØ§Øª Ø§Ù„Ø£Ø®ÙŠØ±Ø©
    """
    # Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø°ÙƒØ±ÙŠØ§Øª Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© (ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø­Ù‚ÙŠÙ‚ÙŠ)
    random_vector = np.random.randn(1024)
    memories = utopia_system.living_memory.retrieve_memories(random_vector, limit=limit)
    return {"memories": memories, "count": len(memories)}

# ============ MAIN ENTRY POINT ============
if __name__ == "__main__":
    logger.info("ğŸš€ Starting 3á¸ŒÆâ˜…Å”Ã’Ã˜á¹¬ - UTOPIA-EDU System...")
    logger.info(f"ğŸ“ Config directory: {CONFIG_DIR}")
    logger.info(f"ğŸ“ Logs directory: {LOGS_DIR}")
    
    uvicorn.run(
        app,
        host="127.0.0.1",
        port=8000,
        log_level="info"
    )
